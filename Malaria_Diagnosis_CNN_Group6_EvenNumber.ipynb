{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C_hxzrVpanrY"
   },
   "source": [
    "# Deep Learning for Malaria Diagnosis\n",
    "This notebook is inspired by works of (Sivaramakrishnan Rajaraman  et al., 2018) and (Jason Brownlee, 2019). Acknowledge to NIH and Bangalor Hospital who make available this malaria dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4DyHvXlda9rH"
   },
   "source": [
    "Malaria is an infectuous disease caused by parasites that are transmitted to people through the bites of infected female Anopheles mosquitoes.\n",
    "\n",
    "The Malaria burden with some key figures:\n",
    "<font color='red'>\n",
    "* More than 219 million cases\n",
    "* Over 430 000 deaths in 2017 (Mostly: children & pregnants)\n",
    "* 80% in 15 countries of Africa & India\n",
    "  </font>\n",
    "\n",
    "![MalariaBurd](https://github.com/habiboulaye/ai-labs/blob/master/malaria-diagnosis/doc-images/MalariaBurden.png?raw=1)\n",
    "\n",
    "The malaria diagnosis is performed using blood test:\n",
    "* Collect patient blood smear\n",
    "* Microscopic visualisation of the parasit\n",
    "\n",
    "![MalariaDiag](https://github.com/habiboulaye/ai-labs/blob/master/malaria-diagnosis/doc-images/MalariaDiag.png?raw=1)\n",
    "  \n",
    "Main issues related to traditional diagnosis:\n",
    "<font color='#ed7d31'>\n",
    "* resource-constrained regions\n",
    "* time needed and delays\n",
    "* diagnosis accuracy and cost\n",
    "</font>\n",
    "\n",
    "The objective of this notebook is to apply modern deep learning techniques to perform medical image analysis for malaria diagnosis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a5qBTeqkrJ88"
   },
   "source": [
    "*This notebook is inspired by works of (Sivaramakrishnan Rajaraman  et al., 2018), (Adrian Rosebrock, 2018) and (Jason Brownlee, 2019)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4K5rb4bmdMRf"
   },
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jxaLbRUnYWTm"
   },
   "outputs": [],
   "source": [
    "#Mount the local drive project_forder\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')\n",
    "!ls \"/content/drive/My Drive/Colab Notebooks/10xDS/Projects/malaria-diagnosis/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oIfORUX7ccHI"
   },
   "outputs": [],
   "source": [
    "# Use GPU: Please check if the outpout is '/device:GPU:0'\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "tf.test.gpu_device_name()\n",
    "#from tensorflow.python.client import device_lib\n",
    "#device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gp1o6Cd7dV6Z"
   },
   "source": [
    "## Populating namespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_4Ph8e1uojEC"
   },
   "outputs": [],
   "source": [
    "# Importing basic libraries\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.image import imread\n",
    "%matplotlib inline\n",
    "\n",
    "# Metrics utilities\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    roc_curve,\n",
    "    auc,\n",
    " )\n",
    "\n",
    "# Importing the Keras libraries and packages\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Convolution2D as Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SOvmLtdRgSIb"
   },
   "outputs": [],
   "source": [
    "# Define the useful paths for data accessibility\n",
    "ai_project = '.' #\"/content/drive/My Drive/Colab Notebooks/ai-labs/malaria-diagnosis\"\n",
    "cell_images_dir = os.path.join(ai_project,'cell_images')\n",
    "training_path = os.path.join(ai_project,'train')\n",
    "testing_path = os.path.join(ai_project,'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11DKlCJcj31w"
   },
   "source": [
    "## Prepare DataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "midATIuUq7H7"
   },
   "source": [
    "### *Download* DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eCT2ogQdeHPW"
   },
   "outputs": [],
   "source": [
    "# Download the data in the allocated google cloud-server. If already down, turn downloadData=False\n",
    "downloadData = True\n",
    "if downloadData == True:\n",
    "  indrive = False\n",
    "  if indrive == True:\n",
    "    !wget https://data.lhncbc.nlm.nih.gov/public/Malaria/cell_images.zip -P \"/content/drive/My Drive/Colab Notebooks/ai-labs/malaria-diagnosis\"\n",
    "    !unzip \"/content/drive/My Drive/Colab Notebooks/ai-labs/malaria-diagnosis/cell_images.zip\" -d \"/content/drive/My Drive/Colab Notebooks/ai-labs/malaria-diagnosis/\"\n",
    "    !ls \"/content/drive/My Drive/Colab Notebooks/ai-labs/malaria-diagnosis\"\n",
    "  else: #incloud google server\n",
    "    !rm -rf cell_images.*\n",
    "    !wget https://data.lhncbc.nlm.nih.gov/public/Malaria/cell_images.zip\n",
    "    !unzip cell_images.zip >/dev/null 2>&1\n",
    "    !ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D1LUJGE9U2vW"
   },
   "source": [
    "## Baseline CNN Model\n",
    "Define a basic ConvNet defined with ConvLayer: Conv2D => MaxPooling2D followed by Flatten => Dense => Dense(output)\n",
    "\n",
    "![ConvNet](https://github.com/habiboulaye/ai-labs/blob/master/malaria-diagnosis/doc-images/ConvNet.png?raw=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple CNN Baseline Setup\n",
    "Prepare a train and validation split from the raw `cell_images` directory without applying any augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "\n",
    "data_dir = Path(cell_images_dir)\n",
    "if not data_dir.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Expected dataset at {data_dir}. Run the download cell before building the baseline model.\"\n",
    "    )\n",
    "\n",
    "img_height = 128\n",
    "img_width = 128\n",
    "batch_size = 32\n",
    "seed = 42\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=seed,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    label_mode=\"binary\",\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=seed,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    label_mode=\"binary\",\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "print(f\"Detected classes: {class_names}\")\n",
    "\n",
    "autotune = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.prefetch(autotune)\n",
    "val_ds = val_ds.prefetch(autotune)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Simple CNN\n",
    "Stack two convolution blocks followed by a small dense head for binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    tf.keras.layers.Rescaling(1.0 / 255, input_shape=(img_height, img_width, 3)),\n",
    "    Conv2D(16, (3, 3), activation=\"relu\"),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(32, (3, 3), activation=\"relu\"),\n",
    "    MaxPooling2D(),\n",
    "    Flatten(),\n",
    "    Dense(64, activation=\"relu\"),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Baseline Model\n",
    "Fit the network on the training data and monitor validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Baseline\n",
    "Report validation performance and inspect learning curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_accuracy = model.evaluate(val_ds)\n",
    "print(f\"Validation loss: {val_loss:.4f}\")\n",
    "print(f\"Validation accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "pyplot.figure(figsize=(10, 4))\n",
    "pyplot.subplot(1, 2, 1)\n",
    "pyplot.plot(history.history[\"loss\"], label=\"train\")\n",
    "pyplot.plot(history.history[\"val_loss\"], label=\"val\")\n",
    "pyplot.title(\"Loss\")\n",
    "pyplot.xlabel(\"Epoch\")\n",
    "pyplot.ylabel(\"Cross-Entropy\")\n",
    "pyplot.legend()\n",
    "\n",
    "pyplot.subplot(1, 2, 2)\n",
    "pyplot.plot(history.history[\"accuracy\"], label=\"train\")\n",
    "pyplot.plot(history.history[\"val_accuracy\"], label=\"val\")\n",
    "pyplot.title(\"Accuracy\")\n",
    "pyplot.xlabel(\"Epoch\")\n",
    "pyplot.ylabel(\"Accuracy\")\n",
    "pyplot.legend()\n",
    "pyplot.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Metrics Table\n",
    "Aggregate accuracy, precision, recall, and F1-score on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_batches = []\n",
    "y_prob_batches = []\n",
    "\n",
    "for batch_images, batch_labels in val_ds:\n",
    "    y_true_batches.append(batch_labels.numpy())\n",
    "    batch_probs = model(batch_images, training=False).numpy().ravel()\n",
    "    y_prob_batches.append(batch_probs)\n",
    "\n",
    "y_true = np.concatenate(y_true_batches)\n",
    "y_prob = np.concatenate(y_prob_batches)\n",
    "y_pred = (y_prob >= 0.5).astype(int)\n",
    "\n",
    "metrics_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Metric\": [\"Accuracy\", \"Precision\", \"Recall\", \"F1-score\"],\n",
    "        \"Value\": [\n",
    "            accuracy_score(y_true, y_pred),\n",
    "            precision_score(y_true, y_pred, zero_division=0),\n",
    "            recall_score(y_true, y_pred, zero_division=0),\n",
    "            f1_score(y_true, y_pred, zero_division=0),\n",
    "        ],\n",
    "    }\n",
    ").set_index(\"Metric\")\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "roc_fpr, roc_tpr, _ = roc_curve(y_true, y_prob)\n",
    "roc_auc = auc(roc_fpr, roc_tpr)\n",
    "\n",
    "display(metrics_df.style.format({\"Value\": \"{:.4f}\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric Interpretation\n",
    "Summarize how the baseline balances sensitivity and specificity using the aggregate metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = cm.ravel()\n",
    "specificity = tn / (tn + fp) if (tn + fp) else 0.0\n",
    "per_class_recall = np.divide(\n",
    "    np.diag(cm),\n",
    "    cm.sum(axis=1),\n",
    "    out=np.zeros(cm.shape[0], dtype=float),\n",
    "    where=cm.sum(axis=1) != 0,\n",
    " )\n",
    "\n",
    "print(\n",
    "    \"Baseline CNN validation summary:\"\n",
    "    f\" accuracy={metrics_df.loc['Accuracy', 'Value']:.4f},\"\n",
    "    f\" precision={metrics_df.loc['Precision', 'Value']:.4f},\"\n",
    "    f\" recall (sensitivity)={metrics_df.loc['Recall', 'Value']:.4f},\"\n",
    "    f\" F1={metrics_df.loc['F1-score', 'Value']:.4f},\"\n",
    "    f\" specificity (true negative rate)={specificity:.4f}.\"\n",
    " )\n",
    "\n",
    "for class_name, recall_value in zip(class_names, per_class_recall):\n",
    "    print(f\"Class '{class_name}' recall={recall_value:.4f}\")\n",
    "\n",
    "print(\n",
    "    f\"ROC AUC={roc_auc:.4f} highlights the model's ability to balance sensitivity and specificity across thresholds.\"\n",
    " )\n",
    "print(\n",
    "    f\"False positives: {fp} | False negatives: {fn} — use this balance to decide if threshold tuning is needed for clinical priorities.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "Visualize class-wise predictions to identify error patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.figure(figsize=(5, 5))\n",
    "image = pyplot.imshow(cm, interpolation=\"nearest\", cmap=\"Blues\")\n",
    "pyplot.title(\"Confusion Matrix (Validation)\")\n",
    "pyplot.colorbar(image, fraction=0.046, pad=0.04)\n",
    "tick_marks = np.arange(len(class_names))\n",
    "pyplot.xticks(tick_marks, class_names, rotation=45)\n",
    "pyplot.yticks(tick_marks, class_names)\n",
    "\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        pyplot.text(\n",
    "            j,\n",
    "            i,\n",
    "            cm[i, j],\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            color=\"black\",\n",
    "            fontsize=10,\n",
    "        )\n",
    "\n",
    "pyplot.ylabel(\"True label\")\n",
    "pyplot.xlabel(\"Predicted label\")\n",
    "pyplot.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Curve\n",
    "Evaluate the sensitivity-specificity trade-off across thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.figure(figsize=(6, 6))\n",
    "pyplot.plot(roc_fpr, roc_tpr, label=f\"AUC = {roc_auc:.4f}\")\n",
    "pyplot.plot([0, 1], [0, 1], \"k--\", label=\"Chance\")\n",
    "pyplot.xlim([0.0, 1.0])\n",
    "pyplot.ylim([0.0, 1.01])\n",
    "pyplot.xlabel(\"False Positive Rate\")\n",
    "pyplot.ylabel(\"True Positive Rate\")\n",
    "pyplot.title(\"ROC Curve (Validation)\")\n",
    "pyplot.legend(loc=\"lower right\")\n",
    "pyplot.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "pyplot.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "OHUcNb15U2vT",
    "WQPM3U9XU2vr"
   ],
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
