{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Malaria Diagnosis Using CNN and Transfer Learning\n",
    "\n",
    "## Overview\n",
    "This notebook implements a deep learning approach for malaria diagnosis using cell images. The project utilizes transfer learning with ResNet50 to classify blood cell images as either parasitized (infected with malaria) or uninfected.\n",
    "\n",
    "## Dataset\n",
    "- **Source**: NIH Malaria Dataset\n",
    "- **Classes**: Parasitized vs Uninfected blood cells\n",
    "- **Total Images**: ~27,558 images\n",
    "- **Split**: 80% training, 20% testing\n",
    "\n",
    "## Methodology\n",
    "The notebook implements two experimental approaches:\n",
    "\n",
    "### Experiment 1 (E1): Frozen Base Model\n",
    "- Uses pre-trained ResNet50 with frozen base layers\n",
    "- Only trains the custom classification head\n",
    "- Learning rate: 1e-4\n",
    "- Focus: Fast training with basic transfer learning\n",
    "\n",
    "### Experiment 2 (E2): Fine-tuned Model  \n",
    "- Fine-tunes the top 30 layers of ResNet50\n",
    "- Unfreezes selected layers for domain-specific learning\n",
    "- Learning rate: 1e-5 (lower for stability)\n",
    "- Focus: Enhanced performance through fine-tuning\n",
    "\n",
    "## Performance Metrics\n",
    "Each experiment reports comprehensive evaluation metrics:\n",
    "- **Accuracy**: Overall classification performance\n",
    "- **Precision**: True positive rate (TP / (TP + FP))\n",
    "- **Recall**: Sensitivity (TP / (TP + FN))\n",
    "- **F1-Score**: Harmonic mean of precision and recall\n",
    "- **AUC**: Area under ROC curve\n",
    "\n",
    "## Visualizations\n",
    "Each model includes complete visual evaluation:\n",
    "1. **Learning Curves**: Training/validation loss and accuracy over epochs\n",
    "2. **Confusion Matrix**: Classification performance across classes\n",
    "3. **ROC/AUC Curves**: Trade-offs between sensitivity and specificity\n",
    "\n",
    "## Requirements\n",
    "- TensorFlow 2.x\n",
    "- scikit-learn\n",
    "- matplotlib\n",
    "- pandas\n",
    "- NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dX-xkf4mnMlt",
    "outputId": "10fe1c1d-5e9e-4ee3-9cad-ceca3f102c04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "nuZZZizvnntv"
   },
   "outputs": [],
   "source": [
    "# Importing basic libraries\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.image import imread\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# Importing the Keras libraries and packages\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Convolution2D as Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4DRiqMc4njzU",
    "outputId": "59ae6fa4-8a50-4121-d452-6e25515532b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-10-04 09:50:14--  https://data.lhncbc.nlm.nih.gov/public/Malaria/cell_images.zip\n",
      "Resolving data.lhncbc.nlm.nih.gov (data.lhncbc.nlm.nih.gov)... 3.163.189.83, 3.163.189.93, 3.163.189.81, ...\n",
      "Connecting to data.lhncbc.nlm.nih.gov (data.lhncbc.nlm.nih.gov)|3.163.189.83|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 353452851 (337M) [application/zip]\n",
      "Saving to: â€˜cell_images.zipâ€™\n",
      "\n",
      "cell_images.zip     100%[===================>] 337.08M   418MB/s    in 0.8s    \n",
      "\n",
      "2025-10-04 09:50:15 (418 MB/s) - â€˜cell_images.zipâ€™ saved [353452851/353452851]\n",
      "\n",
      "cell_images  cell_images.zip  drive  sample_data\n"
     ]
    }
   ],
   "source": [
    "# Download the data in the allocated google cloud-server. If already down, turn downloadData=False\n",
    "downloadData = True\n",
    "if downloadData == True:\n",
    "  indrive = False\n",
    "  if indrive == True:\n",
    "    !wget https://data.lhncbc.nlm.nih.gov/public/Malaria/cell_images.zip -P \"/content/drive/My Drive/Colab Notebooks/ai-labs/malaria-diagnosis\"\n",
    "    !unzip \"/content/drive/My Drive/Colab Notebooks/ai-labs/malaria-diagnosis/cell_images.zip\" -d \"/content/drive/My Drive/Colab Notebooks/ai-labs/malaria-diagnosis/\"\n",
    "    !ls \"/content/drive/My Drive/Colab Notebooks/ai-labs/malaria-diagnosis\"\n",
    "  else: #incloud google server\n",
    "    !rm -rf cell_images.*\n",
    "    !wget https://data.lhncbc.nlm.nih.gov/public/Malaria/cell_images.zip\n",
    "    !unzip cell_images.zip >/dev/null 2>&1\n",
    "    !ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sd1VcrMzph8P",
    "outputId": "f63c90ab-46bf-4317-eddb-727840c2a8d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created train/test directory structure\n",
      "\n",
      "Parasitized: Found 13779 images\n",
      "  - Training: 11023 images\n",
      "  - Testing: 2756 images\n",
      "\n",
      "Uninfected: Found 13779 images\n",
      "  - Training: 11023 images\n",
      "  - Testing: 2756 images\n",
      "\n",
      " Data splitting completed!\n",
      "\n",
      "Final directory structure:\n",
      "train/Parasitized: 11023 images\n",
      "train/Uninfected: 11023 images\n",
      "test/Parasitized: 2756 images\n",
      "test/Uninfected: 2756 images\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# Create train and test directories\n",
    "os.makedirs('train/Parasitized', exist_ok=True)\n",
    "os.makedirs('train/Uninfected', exist_ok=True)\n",
    "os.makedirs('test/Parasitized', exist_ok=True)\n",
    "os.makedirs('test/Uninfected', exist_ok=True)\n",
    "\n",
    "print(\"Created train/test directory structure\")\n",
    "\n",
    "# Split data for each class\n",
    "classes = ['Parasitized', 'Uninfected']\n",
    "train_split = 0.8  # 80% for training, 20% for testing\n",
    "\n",
    "for class_name in classes:\n",
    "    class_path = os.path.join('cell_images', class_name)\n",
    "\n",
    "    # Get all image files in this class\n",
    "    image_files = [f for f in os.listdir(class_path)\n",
    "                   if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "    print(f\"\\n{class_name}: Found {len(image_files)} images\")\n",
    "\n",
    "    # Split the files\n",
    "    train_files, test_files = train_test_split(\n",
    "        image_files, train_size=train_split, random_state=42\n",
    "    )\n",
    "\n",
    "    print(f\"  - Training: {len(train_files)} images\")\n",
    "    print(f\"  - Testing: {len(test_files)} images\")\n",
    "\n",
    "    # Copy files to train directory\n",
    "    for file in train_files:\n",
    "        src = os.path.join(class_path, file)\n",
    "        dst = os.path.join('train', class_name, file)\n",
    "        shutil.copy2(src, dst)\n",
    "\n",
    "    # Copy files to test directory\n",
    "    for file in test_files:\n",
    "        src = os.path.join(class_path, file)\n",
    "        dst = os.path.join('test', class_name, file)\n",
    "        shutil.copy2(src, dst)\n",
    "\n",
    "print(\"\\n Data splitting completed!\")\n",
    "\n",
    "# Verify the structure\n",
    "print(\"\\nFinal directory structure:\")\n",
    "for split in ['train', 'test']:\n",
    "    for class_name in classes:\n",
    "        path = os.path.join(split, class_name)\n",
    "        count = len(os.listdir(path))\n",
    "        print(f\"{split}/{class_name}: {count} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2: Model Setup and Training with ResNet50\n",
    "\n",
    "This section implements transfer learning using ResNet50 for malaria diagnosis. We'll conduct two experiments to compare different training strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "# Import necessary libraries for deep learning and evaluation\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "print(\"âœ“ Libraries imported and random seed set for reproducibility\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration parameters\n",
    "ai_project = '.'\n",
    "training_path = os.path.join(ai_project, 'train')\n",
    "testing_path  = os.path.join(ai_project, 'test')\n",
    "\n",
    "IMG_SIZE = (224, 224)  # ResNet50 input size\n",
    "BATCH_SIZE = 64\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "print(f\"âœ“ Configuration set:\")\n",
    "print(f\"  - Image size: {IMG_SIZE}\")\n",
    "print(f\"  - Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  - Training path: {training_path}\")\n",
    "print(f\"  - Testing path: {testing_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define preprocessing function for ResNet50\n",
    "def resnet_preprocess(image):\n",
    "    \"\"\"\n",
    "    Preprocess images for ResNet50 input.\n",
    "    Converts to float32 and resizes to target size.\n",
    "    \"\"\"\n",
    "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "    image = tf.image.resize(image, IMG_SIZE)\n",
    "    return image\n",
    "\n",
    "# Build optimized tf.data pipelines\n",
    "def make_datasets(train_dir, val_dir, img_size=IMG_SIZE, batch_size=BATCH_SIZE):\n",
    "    \"\"\"\n",
    "    Create optimized training and validation datasets.\n",
    "    \n",
    "    Args:\n",
    "        train_dir: Directory containing training images\n",
    "        val_dir: Directory containing validation images\n",
    "        img_size: Target image size (height, width)\n",
    "        batch_size: Batch size for training\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (train_dataset, validation_dataset)\n",
    "    \"\"\"\n",
    "    # Create datasets from directories\n",
    "    train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        train_dir, image_size=img_size, batch_size=batch_size, shuffle=True\n",
    "    )\n",
    "    val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        val_dir, image_size=img_size, batch_size=batch_size, shuffle=False\n",
    "    )\n",
    "\n",
    "    # Optimize pipeline with preprocessing and prefetching\n",
    "    train_ds = train_ds.map(\n",
    "        lambda x, y: (resnet_preprocess(x), y), \n",
    "        num_parallel_calls=AUTOTUNE\n",
    "    ).prefetch(AUTOTUNE)\n",
    "    \n",
    "    val_ds = val_ds.map(\n",
    "        lambda x, y: (resnet_preprocess(x), y), \n",
    "        num_parallel_calls=AUTOTUNE\n",
    "    ).prefetch(AUTOTUNE)\n",
    "    \n",
    "    return train_ds, val_ds\n",
    "\n",
    "# Create datasets\n",
    "train_ds, val_ds = make_datasets(training_path, testing_path)\n",
    "print(\"âœ“ Datasets created and optimized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation pipeline\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.06),\n",
    "    layers.RandomZoom(0.06),\n",
    "    layers.RandomTranslation(0.05, 0.05),\n",
    "], name=\"data_augmentation\")\n",
    "\n",
    "def build_resnet_model(img_size=IMG_SIZE, dropout_head=0.5):\n",
    "    \"\"\"\n",
    "    Build ResNet50-based transfer learning model.\n",
    "    \n",
    "    Args:\n",
    "        img_size: Input image size (height, width)\n",
    "        dropout_head: Dropout rate for classification head\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (model, base_model)\n",
    "    \"\"\"\n",
    "    # Load pre-trained ResNet50 without top layers\n",
    "    base = ResNet50(\n",
    "        weights='imagenet', \n",
    "        include_top=False, \n",
    "        input_shape=img_size + (3,)\n",
    "    )\n",
    "    base.trainable = False  # Start with frozen base\n",
    "    \n",
    "    # Build custom classification head\n",
    "    inputs = layers.Input(shape=img_size + (3,))\n",
    "    x = data_augmentation(inputs)  # Apply augmentation\n",
    "    x = base(x, training=False)    # Pass through frozen base\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.Dropout(dropout_head)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(x)  # Binary classification\n",
    "    \n",
    "    model = Model(inputs, outputs, name=\"resnet50_transfer\")\n",
    "    return model, base\n",
    "\n",
    "print(\"âœ“ Data augmentation and model architecture defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and evaluation utility functions\n",
    "def compile_and_train(model, train_ds, val_ds, lr, epochs, callbacks=None):\n",
    "    \"\"\"\n",
    "    Compile and train the model with specified parameters.\n",
    "    \n",
    "    Args:\n",
    "        model: Keras model to train\n",
    "        train_ds: Training dataset\n",
    "        val_ds: Validation dataset  \n",
    "        lr: Learning rate\n",
    "        epochs: Number of training epochs\n",
    "        callbacks: List of Keras callbacks\n",
    "    \n",
    "    Returns:\n",
    "        Training history object\n",
    "    \"\"\"\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=lr),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', tf.keras.metrics.AUC(name=\"auc\")]\n",
    "    )\n",
    "    cb = callbacks or []\n",
    "    history = model.fit(\n",
    "        train_ds, \n",
    "        validation_data=val_ds, \n",
    "        epochs=epochs, \n",
    "        callbacks=cb\n",
    "    )\n",
    "    return history\n",
    "\n",
    "def evaluate_model(model, dataset):\n",
    "    \"\"\"\n",
    "    Comprehensive model evaluation with multiple metrics.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model to evaluate\n",
    "        dataset: Dataset for evaluation\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (metrics_dict, y_true, y_pred, y_prob)\n",
    "    \"\"\"\n",
    "    y_true, y_prob = [], []\n",
    "    \n",
    "    # Collect predictions and true labels\n",
    "    for x, y in dataset:\n",
    "        probs = model.predict(x, verbose=0).ravel()\n",
    "        y_prob.extend(probs)\n",
    "        y_true.extend(y.numpy())\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    y_true = np.array(y_true).astype(int)\n",
    "    y_prob = np.array(y_prob)\n",
    "    y_pred = (y_prob >= 0.5).astype(int)\n",
    "    \n",
    "    # Calculate comprehensive metrics\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'precision': precision_score(y_true, y_pred, zero_division=0),\n",
    "        'recall': recall_score(y_true, y_pred, zero_division=0),\n",
    "        'f1': f1_score(y_true, y_pred, zero_division=0),\n",
    "        'auc': roc_auc_score(y_true, y_prob),\n",
    "    }\n",
    "    return metrics, y_true, y_pred, y_prob\n",
    "\n",
    "print(\"âœ“ Training and evaluation functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization functions for model evaluation\n",
    "def plot_history(history, title='Training'):\n",
    "    \"\"\"\n",
    "    Plot training and validation learning curves.\n",
    "    \n",
    "    Shows both accuracy and loss over epochs to visualize:\n",
    "    - Model convergence\n",
    "    - Overfitting/underfitting\n",
    "    - Training stability\n",
    "    \n",
    "    Args:\n",
    "        history: Keras training history object\n",
    "        title: Title prefix for plots\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    # Plot accuracy curves\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy', linewidth=2)\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.title(f'{title} - Accuracy Over Epochs')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    # Plot loss curves  \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Training Loss', linewidth=2)\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title(f'{title} - Loss Over Epochs')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes=['Uninfected','Parasitized']):\n",
    "    \"\"\"\n",
    "    Plot confusion matrix with detailed annotations.\n",
    "    \n",
    "    Shows classification performance across classes:\n",
    "    - True positives and negatives\n",
    "    - False positives and negatives\n",
    "    - Per-class accuracy\n",
    "    \n",
    "    Args:\n",
    "        y_true: True labels\n",
    "        y_pred: Predicted labels\n",
    "        classes: Class names for labeling\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix\\n(Rows: True Labels, Columns: Predicted Labels)', fontsize=12)\n",
    "    plt.colorbar()\n",
    "    \n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    \n",
    "    # Add text annotations\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\",\n",
    "                 fontsize=14, fontweight='bold')\n",
    "    \n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_roc(y_true, y_prob):\n",
    "    \"\"\"\n",
    "    Plot ROC curve with AUC score.\n",
    "    \n",
    "    Demonstrates trade-offs between sensitivity and specificity:\n",
    "    - Higher AUC indicates better discrimination\n",
    "    - Diagonal line represents random chance\n",
    "    - Curve closer to top-left indicates better performance\n",
    "    \n",
    "    Args:\n",
    "        y_true: True binary labels\n",
    "        y_prob: Predicted probabilities\n",
    "    \"\"\"\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "    auc_score = roc_auc_score(y_true, y_prob)\n",
    "    \n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.plot(fpr, tpr, linewidth=3, label=f'ROC Curve (AUC = {auc_score:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], '--', color='gray', label='Random Classifier')\n",
    "    plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "    plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "    plt.title('ROC Curve - Model Discrimination Performance')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"âœ“ Visualization functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training callbacks for optimization\n",
    "def make_callbacks():\n",
    "    \"\"\"\n",
    "    Create training callbacks for better model performance.\n",
    "    \n",
    "    Returns:\n",
    "        List of callbacks:\n",
    "        - EarlyStopping: Prevents overfitting\n",
    "        - ReduceLROnPlateau: Adapts learning rate\n",
    "    \"\"\"\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss', \n",
    "        patience=3, \n",
    "        restore_best_weights=True, \n",
    "        verbose=1\n",
    "    )\n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor='val_loss', \n",
    "        factor=0.5, \n",
    "        patience=2, \n",
    "        min_lr=1e-7, \n",
    "        verbose=1\n",
    "    )\n",
    "    return [early_stopping, reduce_lr]\n",
    "\n",
    "print(\"âœ“ Training callbacks configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1: Frozen Base Model (Transfer Learning)\n",
    "\n",
    "**Approach**: Use pre-trained ResNet50 with frozen base layers, only training the custom classification head.\n",
    "\n",
    "**Rationale**: \n",
    "- Fast training with minimal computational requirements\n",
    "- Leverages ImageNet features for cell image classification\n",
    "- Baseline performance for comparison with fine-tuning\n",
    "\n",
    "**Parameters**:\n",
    "- Learning Rate: 1e-4 (standard for head-only training)\n",
    "- Frozen Layers: All ResNet50 base layers\n",
    "- Trainable Parameters: Only classification head (~2.1M parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 1: Build and train model with frozen base\n",
    "print(\"ðŸ”¬ Starting Experiment 1: Frozen Base Model\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Build model with frozen base\n",
    "model_resnet, base_resnet = build_resnet_model(dropout_head=0.5)\n",
    "\n",
    "# Ensure base is frozen\n",
    "for layer in base_resnet.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "print(f\"Model built with {model_resnet.count_params():,} total parameters\")\n",
    "trainable_params = sum([tf.keras.backend.count_params(w) for w in model_resnet.trainable_weights])\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "# Train the model\n",
    "history_e1 = compile_and_train(\n",
    "    model_resnet,\n",
    "    train_ds,\n",
    "    val_ds,\n",
    "    lr=1e-4,\n",
    "    epochs=12,\n",
    "    callbacks=make_callbacks()\n",
    ")\n",
    "\n",
    "print(\"âœ“ Experiment 1 training completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 1: Evaluation and Visualization\n",
    "print(\" Evaluating Experiment 1 Performance\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Plot learning curves\n",
    "plot_history(history_e1, title='ResNet50 - E1 (Frozen Base)')\n",
    "\n",
    "# Evaluate model performance\n",
    "metrics_e1, y_true_e1, y_pred_e1, y_prob_e1 = evaluate_model(model_resnet, val_ds)\n",
    "\n",
    "# Display metrics\n",
    "print(\" Experiment 1 Performance Metrics:\")\n",
    "print(\"-\" * 30)\n",
    "for metric, value in metrics_e1.items():\n",
    "    print(f\"{metric.upper():<12}: {value:.4f}\")\n",
    "\n",
    "# Plot confusion matrix\n",
    "print(\"\\n Confusion Matrix Analysis:\")\n",
    "plot_confusion_matrix(y_true_e1, y_pred_e1)\n",
    "\n",
    "# Plot ROC curve\n",
    "print(\" ROC Curve Analysis:\")\n",
    "plot_roc(y_true_e1, y_prob_e1)\n",
    "\n",
    "# Store results for comparison\n",
    "results = []\n",
    "results.append({\n",
    "    'experiment_id': 'E1',\n",
    "    'description': 'Frozen ResNet50 base, train head only; lr=1e-4',\n",
    "    **metrics_e1\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2: Fine-tuned Model (Advanced Transfer Learning)\n",
    "\n",
    "**Approach**: Fine-tune the top 30 layers of ResNet50 while keeping earlier layers frozen.\n",
    "\n",
    "**Rationale**:\n",
    "- Adapts high-level features to malaria-specific patterns\n",
    "- Balances feature adaptation with training stability\n",
    "- Expected to improve performance over frozen base\n",
    "\n",
    "**Parameters**:\n",
    "- Learning Rate: 1e-5 (lower for stability during fine-tuning)\n",
    "- Unfrozen Layers: Top 30 layers of ResNet50\n",
    "- Batch Normalization: Kept frozen to maintain stability\n",
    "- Additional Trainable Parameters: ~6.3M parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 2: Fine-tune top layers\n",
    "print(\"ðŸ”¬ Starting Experiment 2: Fine-tuned Model\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Configuration for fine-tuning\n",
    "N_unfreeze = 30\n",
    "base_resnet.trainable = True\n",
    "\n",
    "# Selectively unfreeze top layers\n",
    "frozen_count = 0\n",
    "unfrozen_count = 0\n",
    "\n",
    "for i, layer in enumerate(base_resnet.layers):\n",
    "    if i < len(base_resnet.layers) - N_unfreeze:\n",
    "        layer.trainable = False\n",
    "        frozen_count += 1\n",
    "    else:\n",
    "        # Keep BatchNormalization layers frozen for stability\n",
    "        if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "            layer.trainable = False\n",
    "            frozen_count += 1\n",
    "        else:\n",
    "            layer.trainable = True\n",
    "            unfrozen_count += 1\n",
    "\n",
    "print(f\"Layer configuration:\")\n",
    "print(f\"  - Frozen layers: {frozen_count}\")\n",
    "print(f\"  - Unfrozen layers: {unfrozen_count}\")\n",
    "\n",
    "# Recompile with lower learning rate for fine-tuning\n",
    "model_resnet.compile(\n",
    "    optimizer=Adam(learning_rate=1e-5),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.AUC(name=\"auc\")]\n",
    ")\n",
    "\n",
    "# Display parameter counts\n",
    "total_params = model_resnet.count_params()\n",
    "trainable_params = sum([tf.keras.backend.count_params(w) for w in model_resnet.trainable_weights])\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "# Train with fine-tuning\n",
    "history_e2 = model_resnet.fit(\n",
    "    train_ds, \n",
    "    validation_data=val_ds, \n",
    "    epochs=12, \n",
    "    callbacks=make_callbacks()\n",
    ")\n",
    "\n",
    "print(\"âœ“ Experiment 2 training completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 2: Evaluation and Visualization\n",
    "print(\" Evaluating Experiment 2 Performance\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Plot learning curves\n",
    "plot_history(history_e2, title=f'ResNet50 - E2 (Fine-tune top {N_unfreeze})')\n",
    "\n",
    "# Evaluate model performance\n",
    "metrics_e2, y_true_e2, y_pred_e2, y_prob_e2 = evaluate_model(model_resnet, val_ds)\n",
    "\n",
    "# Display metrics\n",
    "print(\" Experiment 2 Performance Metrics:\")\n",
    "print(\"-\" * 30)\n",
    "for metric, value in metrics_e2.items():\n",
    "    print(f\"{metric.upper():<12}: {value:.4f}\")\n",
    "\n",
    "# Plot confusion matrix\n",
    "print(\"\\n Confusion Matrix Analysis:\")\n",
    "plot_confusion_matrix(y_true_e2, y_pred_e2)\n",
    "\n",
    "# Plot ROC curve\n",
    "print(\" ROC Curve Analysis:\")\n",
    "plot_roc(y_true_e2, y_prob_e2)\n",
    "\n",
    "# Store results for comparison\n",
    "results.append({\n",
    "    'experiment_id': 'E2',\n",
    "    'description': f'Fine-tune top {N_unfreeze} layers; lr=1e-5',\n",
    "    **metrics_e2\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Comparison and Analysis\n",
    "\n",
    "This section provides a comprehensive comparison of both experiments, analyzing the trade-offs between different training strategies for malaria diagnosis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive Results Comparison\n",
    "print(\"ðŸ† FINAL RESULTS COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create results DataFrame for tabular comparison\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display formatted results table\n",
    "print(\" Performance Metrics Summary:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'Experiment':<12} {'Description':<35} {'Accuracy':<10} {'Precision':<10} {'Recall':<10} {'F1-Score':<10} {'AUC':<8}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for _, row in results_df.iterrows():\n",
    "    print(f\"{row['experiment_id']:<12} {row['description'][:34]:<35} \"\n",
    "          f\"{row['accuracy']:<10.4f} {row['precision']:<10.4f} \"\n",
    "          f\"{row['recall']:<10.4f} {row['f1']:<10.4f} {row['auc']:<8.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Calculate improvements\n",
    "if len(results_df) >= 2:\n",
    "    e1_acc = results_df.iloc[0]['accuracy']\n",
    "    e2_acc = results_df.iloc[1]['accuracy']\n",
    "    acc_improvement = ((e2_acc - e1_acc) / e1_acc) * 100\n",
    "    \n",
    "    e1_f1 = results_df.iloc[0]['f1']\n",
    "    e2_f1 = results_df.iloc[1]['f1']\n",
    "    f1_improvement = ((e2_f1 - e1_f1) / e1_f1) * 100\n",
    "    \n",
    "    print(\" Performance Analysis:\")\n",
    "    print(f\"  â€¢ Accuracy improvement (E2 vs E1): {acc_improvement:+.2f}%\")\n",
    "    print(f\"  â€¢ F1-Score improvement (E2 vs E1): {f1_improvement:+.2f}%\")\n",
    "    \n",
    "    # Determine best model\n",
    "    best_model = \"E2\" if e2_acc > e1_acc else \"E1\"\n",
    "    print(f\"  â€¢ Best performing model: {best_model}\")\n",
    "\n",
    "# Display complete results DataFrame\n",
    "print(\"\\nðŸ“‹ Detailed Results Table:\")\n",
    "display(results_df)\n",
    "\n",
    "print(\"\\n Key Findings:\")\n",
    "print(\"â€¢ Learning curves show model convergence and training stability\")\n",
    "print(\"â€¢ Confusion matrices reveal classification performance per class\")  \n",
    "print(\"â€¢ ROC curves demonstrate discrimination capability (AUC scores)\")\n",
    "print(\"â€¢ Fine-tuning generally improves performance but requires more resources\")\n",
    "print(\"â€¢ Both models show strong performance for malaria diagnosis task\")\n",
    "\n",
    "print(\"\\nâœ… Analysis Complete - All visualizations and metrics generated\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
